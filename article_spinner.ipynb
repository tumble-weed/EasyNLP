{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Article Spinner\\nWe are going to build a probability model for each word in Amazon reviews, conditioned on its 2 neighbours (context).\\nThus it is called the trigram model.\\nThen we are going to use this probability model to substitute some words in the article with others that\\nhave appeared in the same context. E.g. say 'Dog chase Cat' and 'Dog lick cat' are both appearing in the reviews\\nthen 'lick' can be substituted with 'chase'\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Article Spinner\n",
    "We are going to build a probability model for each word in Amazon reviews, conditioned on its 2 neighbours (context).\n",
    "Thus it is called the trigram model.\n",
    "Then we are going to use this probability model to substitute some words in the article with others that\n",
    "have appeared in the same context. E.g. say 'Dog chase Cat' and 'Dog lick cat' are both appearing in the reviews\n",
    "then 'lick' can be substituted with 'chase'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOrder of operations\\n1. Read in the Amazon reviews, and tokenize\\n2. Make the Context dictionary\\n3. Make the probability tables for each Trigram\\n4. Do the actual spinning\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Order of operations\n",
    "1. Read in the Amazon reviews, and tokenize\n",
    "2. Make the Context dictionary\n",
    "3. Make the probability tables for each Trigram\n",
    "4. Do the actual spinning\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/bs4/__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "\"\"\" No stop word removal , no stemming (for grammatical correctness) \"\"\"\n",
    "pos_review = BeautifulSoup(open('electronics/positive.review').read())\n",
    "pos_review = pos_review.findAll('review_text')\n",
    "tokenized_rev =[]\n",
    "for r in pos_review:\n",
    "    r = r.text\n",
    "    r = r.lower()\n",
    "    tokenized_rev.append(nltk.tokenize.word_tokenize(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Make the trigram dictionary\n",
    "the key is the context, and the value is the words. for e.g. if we have 'Dog chase cat' and 'dog lick cat'\n",
    "then the dictionary will be {(dog,cat):[chase,lick]}\n",
    "\n",
    "\"\"\"\n",
    "trigrams = {} \n",
    "for r in tokenized_rev:\n",
    "    len_r = len(r)\n",
    "    for i in range(1,len_r-2): # we want the 'center' word to be last but one, \n",
    "        context=(r[i-1],r[i+1])# in python indexing this comes to len-1\n",
    "        w = r[i]\n",
    "        if context not in trigrams: # incase this context hasn't been seen before, make the dictionar key a \n",
    "            trigrams[context] = []  # empty list \n",
    "        trigrams[context].extend([w]) # extend the list with this word\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( (u'i', u'running') : [u\"'m\", u'am', u\"'m\", u'was', u\"'m\"] ) ( (u'have', u'made') : [u'been', u'also'] ) ( (u'use', u'battery') : [u'the', u'the'] ) ( (u'want', u'you') : [u'everytime', u'optical'] ) ( (u'think', u'are') : [u'there', u'these'] ) ( (u'.', u'prefer') : [u'i', u'i'] ) ( (u'at', u'times') : [u'all', u'three', u'all', u'all'] ) ( (u\"'\", u'their') : [u'on', u'down'] ) ( (u'played', u'on') : [u'fine', u'once'] ) ( (u'--', u'i') : [u'if', u'-'] )\n"
     ]
    }
   ],
   "source": [
    "\"\"\" see the trigram dictionary\"\"\"\n",
    "i = 0\n",
    "for k,v in trigrams.iteritems(): # you can't do 'for k,v in trigrams' , you have to use iteritems\n",
    "    if len(v) > 1:\n",
    "        print '(',k,':',trigrams[k],')',\n",
    "        i += 1\n",
    "    if i==10:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" make the trigram model \"\"\"\n",
    "trigrams_model = {}\n",
    "ctr = 0\n",
    "for context,words in trigrams.iteritems():\n",
    "    nwords_in_context = len(words)\n",
    "    if nwords_in_context > 1:\n",
    "        word_probs = {}\n",
    "        for w in words:\n",
    "            if w not in word_probs:\n",
    "                word_probs[w] = 0.\n",
    "            word_probs[w] += 1./nwords_in_context\n",
    "        trigrams_model[context] = word_probs\n",
    "        #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( (u',', u'which') : {u\"''\": 0.3333333333333333, u'and': 0.3333333333333333, u'(': 0.3333333333333333} )\n",
      "\n",
      "( (u'to', u'i') : {u'wherever': 0.09090909090909091, u',': 0.09090909090909091, u'bed': 0.09090909090909091, u'.': 0.2727272727272727, u'say': 0.18181818181818182, u'but': 0.09090909090909091, u'which': 0.09090909090909091, u'it': 0.09090909090909091} )\n",
      "\n",
      "( (u'in', u'usb') : {u'the': 0.6666666666666666, u'another': 0.3333333333333333} )\n",
      "\n",
      "( (u'you', u'have') : {u'wont': 0.037037037037037035, u'do': 0.037037037037037035, u\"'ll\": 0.2222222222222222, u'would': 0.037037037037037035, u'to': 0.037037037037037035, u'may': 0.07407407407407407, u'always': 0.037037037037037035, u'never': 0.037037037037037035, u'should': 0.037037037037037035, u'will': 0.1111111111111111, u'also': 0.037037037037037035, u'only': 0.037037037037037035, u'definitely': 0.037037037037037035, u'can': 0.037037037037037035, u'now': 0.037037037037037035, u'might': 0.1111111111111111, u'must': 0.037037037037037035} )\n",
      "\n",
      "( (u'in', u'movie') : {u'a': 0.5, u'windows': 0.5} )\n",
      "\n",
      "( (u'with', u'great') : {u'a': 1.0} )\n",
      "\n",
      "( (u'between', u'and') : {u'cable': 0.125, u'verbatim': 0.125, u'this': 0.25, u'it': 0.125, u',': 0.125, u'touchpad': 0.125, u'fm': 0.125} )\n",
      "\n",
      "( (u'i', u'running') : {u'was': 0.2, u\"'m\": 0.6000000000000001, u'am': 0.2} )\n",
      "\n",
      "( (u'a', u'this') : {u'device': 0.3333333333333333, u'bit': 0.3333333333333333, u'screen': 0.3333333333333333} )\n",
      "\n",
      "( (u'could', u'find') : {u\"n't\": 0.75, u'not': 0.25} )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" see the trigrams model\"\"\"\n",
    "i = 0\n",
    "for k,v in trigrams_model.iteritems(): # you can't do 'for k,v in trigrams' , you have to use iteritems\n",
    "    print '(',k,':',trigrams_model[k],')\\n'\n",
    "    i += 1\n",
    "    if i==10:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'to', u'i') say\n"
     ]
    }
   ],
   "source": [
    "def spin(context):\n",
    "    r = np.random.random() # get a random number between 0-1\n",
    "    try:\n",
    "        word_probs = trigrams_model[context]\n",
    "        cumsum = 0.\n",
    "        for w in word_probs:\n",
    "            cumsum += word_probs[w]\n",
    "            if r<cumsum:\n",
    "                return w\n",
    "    except:\n",
    "        return None\n",
    "print trigrams_model.keys()[1],spin(trigrams_model.keys()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\n",
      "i purchased this unit due to frequent blackouts in my area and 2 power supplies going bad . it will run my cable modem , router , pc , and lcd monitor for 5 minutes . this is more than enough time to save work and shut down . equally important , i know that my electronics are receiving clean power . i feel that this investment is minor compared to the loss of valuable data or the failure of equipment due to a power spike or an irregular power supply . as always , amazon had it to me in < 2 business days\n",
      "\n",
      "Spun\n",
      "i bought this unit prior to frequent blackouts in my area and crank power supplies going strong . i will run my wireless box , router , pc , and the monitor for 5 minutes . this gets higher than expected storage to save work and cools down . equally important , i feel if my electronics are receiving clean power . i found . this case is minor compared to the speakers of valuable data or the back of equipment attached to dedicated power spike or an irregular power outlet . i solid , i delivered wanted took me in the 2 business\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "keep a probability of spinning, say 0.2\n",
    "\"\"\"\n",
    "pspin = 0.8\n",
    "rev = tokenized_rev[0]\n",
    "spun = [rev[0]]\n",
    "\n",
    "for i in range(1,len(rev)-1):\n",
    "    spin_flag = np.random.random()< pspin\n",
    "    if spin_flag:\n",
    "        w = spin((rev[i-1],rev[i+1]))\n",
    "        if w is None:\n",
    "            w = rev[i]\n",
    "    else:\n",
    "        w = rev[i]\n",
    "    spun.extend([w])\n",
    "print 'Original\\n',' '.join(rev)\n",
    "print '\\nSpun\\n',' '.join(spun)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
